{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Shopper Loyalty \n",
    "### Solution to Kaggle's Acquiring Valued Shoppers Challenge\n",
    "*K Madhumathi, Tarun Tater, Tanmayee Narendra*\n",
    "\n",
    "Challenge description -- https://www.kaggle.com/c/acquire-valued-shoppers-challenge\n",
    "\n",
    "Data files may be found here -- https://www.kaggle.com/c/acquire-valued-shoppers-challenge/data\n",
    "\n",
    "For more details about solution, please refer ml_project_report.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "All import Statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import graphlab.aggregate as agg\n",
    "from graphlab import SArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainHistory = gl.SFrame.read_csv(\"trainHistory.csv\")\n",
    "transactions = gl.SFrame.read_csv(\"transactions.csv\")\n",
    "offerData = gl.SFrame.read_csv(\"offers.csv\")\n",
    "trainFeatures = trainHistory.join(offerData, on='offer', how='left') #joining the offer file and trainHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the 'items.csv' file which has products belonging to only those categories or brand or company which have offer on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "loc_offers = \"offers.csv\"\n",
    "loc_transactions = \"transactions.csv\"\n",
    "loc_reduced = \"items.csv\" # will be created\n",
    "\n",
    "def reduce_data(loc_offers, loc_transactions, loc_reduced):\n",
    "\n",
    "    start = datetime.now()  \n",
    "    brands = {}\n",
    "    categories = {}\n",
    "    companies = {}\n",
    "    \n",
    "    for e, line in enumerate( open(loc_offers) ):\n",
    "        a = line.split(\",\")[5]\n",
    "        a = re.sub(\"\"\"\\n\"\"\", \"\", a, re.I|re.S)\n",
    "        brands[ a ] = 1\n",
    "        categories[ line.split(\",\")[1] ] = 1\n",
    "        companies[ line.split(\",\")[3] ] = 1\n",
    "        \n",
    "  #open output file\n",
    "    with open(loc_reduced, \"wb\") as outfile:\n",
    "    #go through transactions file and reduce\n",
    "        for e, line in enumerate( open(loc_transactions) ):\n",
    "            if e == 0:\n",
    "                outfile.write( line ) #print header\n",
    "            else:\n",
    "        #only write when category in offers dict\n",
    "                if ((line.split(\",\")[3] in categories)|(line.split(\",\")[4] in companies)|(line.split(\",\")[5] in brands)):\n",
    "                    outfile.write( line )\n",
    "      #progress\n",
    "            if e % 5000000 == 0:\n",
    "                print e, datetime.now() - start\n",
    "    print e, datetime.now() - start\n",
    "\n",
    "reduce_data(loc_offers, loc_transactions, loc_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading items file in a sframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemsBrand = items[:]\n",
    "itemsCategory = items[:]\n",
    "itemsCompany = items[:]\n",
    "itemsBrand.remove_columns(['chain', 'dept', 'date', 'productsize','productmeasure','category','company'])\n",
    "itemsCategory.remove_columns(['chain', 'dept', 'date', 'productsize','productmeasure','brand','company'])\n",
    "itemsCompany.remove_columns(['chain', 'dept', 'date', 'productsize','productmeasure','category','brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the start and end indices of each user in the items file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "listofIndices = {}\n",
    "lId = []\n",
    "prevId = \"86246\"\n",
    "e1 = 0\n",
    "l = [e1]\n",
    "lStart = []\n",
    "with open(\"items.csv\") as f:\n",
    "    for i in xrange(1):\n",
    "        f.next()\n",
    "    for e, line in enumerate( f ):\n",
    "        if(prevId == line.split(\",\")[0]):\n",
    "            pass\n",
    "        else:\n",
    "            l.append(e)\n",
    "            listofIndices[prevId] = l\n",
    "            lId.append(prevId)\n",
    "            prevId = line.split(\",\")[0]\n",
    "            e1 = e\n",
    "            l = [e1]\n",
    "            lStart.append(int(e1))\n",
    "            \n",
    "l = [e1, e]\n",
    "listofIndices[line.split(\",\")[0]] = l\n",
    "toc = time.time()\n",
    "print (toc - tic)\n",
    "print len(listofIndices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFeatures = gl.SFrame.read_csv(\"trainHistory.csv\")\n",
    "trainFeatures['repeater'] = (trainFeatures['repeater'] == 'f')\n",
    "testFeatures = gl.SFrame.read_csv('testHistory.csv')\n",
    "offerData = gl.SFrame.read_csv(\"offers.csv\")\n",
    "trainFeatures = trainFeatures.join(offerData, on='offer', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "*************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recording brand, category and company for each row in train data\n",
    "tic = time.time()\n",
    "dictStore = {}\n",
    "lIdT = []\n",
    "l = []\n",
    "with open(\"trainFeatures.csv\") as f:\n",
    "    for i in xrange(1):\n",
    "        f.next()\n",
    "    for e, line in enumerate( f ):\n",
    "        l = [int(line.split(\",\")[7]), int(line.split(\",\")[9]), int(line.split(\",\")[11])]\n",
    "        dictStore[int(line.split(\",\")[0])] = l\n",
    "        lIdT.append(int(line.split(\",\")[0]))\n",
    "        toc = time.time()\n",
    "print (toc - tic)\n",
    "print len(dictStore)\n",
    "print len(lIdT)\n",
    "\n",
    "tic = time.time()\n",
    "dictStoreTest = {}\n",
    "lIdTTest = []\n",
    "lTest = []\n",
    "with open(\"testFeatures.csv\") as f:\n",
    "    for i in xrange(1):\n",
    "        f.next()\n",
    "    for e, line in enumerate( f ):\n",
    "        l = [int(line.split(\",\")[5]), int(line.split(\",\")[7]), int(line.split(\",\")[9])]\n",
    "        dictStoreTest[int(line.split(\",\")[0])] = l\n",
    "        lIdTTest.append(int(line.split(\",\")[0]))\n",
    "        toc = time.time()\n",
    "print (toc - tic)\n",
    "print len(dictStoreTest)\n",
    "print len(lIdTTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "*************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9 features : \n",
    "tic = time.time()\n",
    "i = 0\n",
    "listOfValuesBrand = []\n",
    "listOfValuesCompany = []\n",
    "listOfValuesCategory = []\n",
    "keyError = []\n",
    "for x in lIdT:\n",
    "    i = i + 1\n",
    "    presentValues = [0,0,0]\n",
    "    if((i % 400) == 0):\n",
    "        print (time.time()-tic), i\n",
    "    try:\n",
    "        xlist = listofIndices[x]\n",
    "        particularIdBrand = itemsBrand[xlist[0]:xlist[1]]#particular id is a sframe\n",
    "        particularIdCompany = itemsCompany[xlist[0]:xlist[1]]\n",
    "        particularIdCategory = itemsCategory[xlist[0]:xlist[1]]\n",
    "\n",
    "        listDictStore = dictStore[x]\n",
    "        particularIdCategory = particularIdCategory.filter_by([listDictStore[0]], 'category')    \n",
    "        if(len(particularIdCategory)!= 0):\n",
    "            presentValues = [len(particularIdCategory), sum(particularIdCategory['purchasequantity']), sum(particularIdCategory['purchaseamount'])]\n",
    "\n",
    "        listOfValuesCategory.append(presentValues)\n",
    "\n",
    "        particularIdCompany = particularIdCompany.filter_by([listDictStore[1]], 'company')    \n",
    "        if(len(particularIdCompany)!= 0):\n",
    "            presentValues = [len(particularIdCompany), sum(particularIdCompany['purchasequantity']), sum(particularIdCompany['purchaseamount'])]\n",
    "        listOfValuesCompany.append(presentValues)\n",
    "        \n",
    "        particularIdBrand = particularIdBrand.filter_by([listDictStore[2]], 'brand')    \n",
    "        if(len(particularIdBrand)!= 0):\n",
    "            presentValues = [len(particularIdBrand), sum(particularIdBrand['purchasequantity']), sum(particularIdBrand['purchaseamount'])]\n",
    "        listOfValuesBrand.append(presentValues)\n",
    "    \n",
    "    except:\n",
    "        keyError.append(x)\n",
    "        print x\n",
    "\n",
    "toc = time.time()\n",
    "print (toc-tic)\n",
    "\n",
    "presentValues=[0,0,0]\n",
    "for x in keyError:\n",
    "    position = lIdT.index(x)\n",
    "    listOfValuesBrand.insert(position, presentValues)\n",
    "    listOfValuesCategory.insert(position, presentValues)\n",
    "    listOfValuesCompany.insert(position, presentValues)\n",
    "    \n",
    "numCategoryTest = []\n",
    "quanCategoryTest = []\n",
    "amountCategoryTest = []\n",
    "for x in listOfValuesCategoryTest:\n",
    "    numCategoryTest.append(x[0])\n",
    "    quanCategoryTest.append(x[1])\n",
    "    amountCategoryTest.append(x[2])\n",
    "    \n",
    "numCompanyTest = []\n",
    "quanCompanyTest = []\n",
    "amountCompanyTest = []\n",
    "for x in listOfValuesCompanyTest:\n",
    "    numCompanyTest.append(x[0])\n",
    "    quanCompanyTest.append(x[1])\n",
    "    amountCompanyTest.append(x[2])\n",
    "    \n",
    "numBrandTest = []\n",
    "quanBrandTest = []\n",
    "amountBrandTest = []\n",
    "for x in listOfValuesBrandTest:\n",
    "    numBrandTest.append(x[0])\n",
    "    quanBrandTest.append(x[1])\n",
    "    amountBrandTest.append(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "*************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding individual Feature to sframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = gl.SFrame()\n",
    "userId = SArray(lIdT)\n",
    "training.add_column(userId)\n",
    "Testing = gl.SFrame()\n",
    "userId = SArray(lIdTTest)\n",
    "Testing.add_column(userId)\n",
    "\n",
    "numCompany = SArray(numCompany)\n",
    "training.add_column(numCompany)\n",
    "numCategory = SArray(numCategory)\n",
    "training.add_column(numCategory)\n",
    "numBrand = SArray(numBrand)\n",
    "training.add_column(numBrand)\n",
    "\n",
    "numCompanyTest = SArray(numCompanyTest)\n",
    "Testing.add_column(numCompanyTest)\n",
    "numCategoryTest = SArray(numCategoryTest)\n",
    "Testing.add_column(numCategoryTest)\n",
    "numBrandTest = SArray(numBrandTest)\n",
    "Testing.add_column(numBrandTest)\n",
    "\n",
    "numBrandTest = SArray(numBrandTest)\n",
    "Testing.add_column(numBrandTest)\n",
    "\n",
    "Testing.rename({'X1' : 'id', 'X2' : 'numCompany', 'X3' : 'numCategory', 'X4' : 'numBrand'})\n",
    "\n",
    "quanCompany = SArray(quanCompany)\n",
    "training.add_column(quanCompany)\n",
    "quanCategory = SArray(quanCategory)\n",
    "training.add_column(quanCategory)\n",
    "quanBrand = SArray(quanBrand)\n",
    "training.add_column(quanBrand)\n",
    "\n",
    "quanCompanyTest = SArray(quanCompanyTest)\n",
    "Testing.add_column(quanCompanyTest)\n",
    "quanCategoryTest = SArray(quanCategoryTest)\n",
    "Testing.add_column(quanCategoryTest)\n",
    "quanBrandTest = SArray(quanBrandTest)\n",
    "Testing.add_column(quanBrandTest)\n",
    "\n",
    "Testing.rename({'X5' : 'quanCompany', 'X6' : 'quanCategory', 'X7' : 'quanBrand'})\n",
    "\n",
    "amountCompany = SArray(amountCompany)\n",
    "training.add_column(amountCompany)\n",
    "amountCategory = SArray(amountCategory)\n",
    "training.add_column(amountCategory)\n",
    "amountBrand = SArray(amountBrand)\n",
    "training.add_column(amountBrand)\n",
    "\n",
    "amountCompanyTest = SArray(amountCompanyTest)\n",
    "Testing.add_column(amountCompanyTest)\n",
    "amountCategoryTest = SArray(amountCategoryTest)\n",
    "Testing.add_column(amountCategoryTest)\n",
    "amountBrandTest = SArray(amountBrandTest)\n",
    "Testing.add_column(amountBrandTest)\n",
    "\n",
    "Testing.rename({'X8' : 'amountCompany', 'X9' : 'amountCategory', 'X10' : 'amountBrand'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "****************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the sframes and loading back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing.save('./testing')\n",
    "Testing.save('./testing')\n",
    "\n",
    "training = gl.load_sframe('./training')\n",
    "testing = gl.load_sframe('./Testing')\n",
    "trainHistory = gl.SFrame.read_csv(\"trainHistory.csv\")\n",
    "offerData = gl.SFrame.read_csv(\"offers.csv\")\n",
    "trainFeatures = trainHistory.join(offerData, on='offer', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************\n",
    "mainpulating sframe to have features as strings and integers as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFeatures['repeater'] = (trainFeatures['repeater'] == 'f')\n",
    "trainFeatures.remove_column('repeattrips')\n",
    "training1 = training[:]\n",
    "training.remove_column('id')\n",
    "trainFeatures.add_columns(training)\n",
    "temp = trainFeatures[:]\n",
    "temp.remove_columns(['id','brand', 'company', 'category', 'offer', 'chain', 'market'])\n",
    "trainFeaturesUpdated = gl.SFrame()\n",
    "trainFeaturesUpdated.add_columns([trainFeatures['id'].astype(str), trainFeatures['brand'].astype(str), trainFeatures['company'].astype(str), trainFeatures['category'].astype(str), trainFeatures['offer'].astype(str), trainFeatures['chain'].astype(str), trainFeatures['market'].astype(str)], ['id','brand', 'company', 'category', 'offer', 'chain', 'market'])\n",
    "\n",
    "temp = testFeatures[:]\n",
    "temp.remove_columns(['id','brand', 'company', 'category', 'offer', 'chain', 'market'])\n",
    "testFeaturesUpdated = gl.SFrame()\n",
    "testFeaturesUpdated.add_columns([testFeatures['id'].astype(str), testFeatures['brand'].astype(str), testFeatures['company'].astype(str), testFeatures['category'].astype(str), testFeatures['offer'].astype(str), testFeatures['chain'].astype(str), testFeatures['market'].astype(str)], ['id','brand', 'company', 'category', 'offer', 'chain', 'market'])\n",
    "testFeaturesUpdated.add_columns(temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hasNeverBoughtCompany = -1*(trainFeaturesUpdated['numCompany'] == 0)\n",
    "hasNeverBoughtBrand = -1*(trainFeaturesUpdated['numBrand'] == 0)\n",
    "hasNeverBoughtCategory = -1*(trainFeaturesUpdated['numCategory'] == 0)\n",
    "\n",
    "hasBoughtCompanyBrand = 1*((trainFeaturesUpdated['numCompany'] > 0)*(trainFeaturesUpdated['numBrand'] > 0))\n",
    "hasBoughtCompanyCategory = 1*((trainFeaturesUpdated['numCompany'] > 0)*(trainFeaturesUpdated['numCategory'] > 0))\n",
    "hasBoughtCategoryBrand = 1*((trainFeaturesUpdated['numCategory'] > 0)*(trainFeaturesUpdated['numBrand'] > 0))\n",
    "\n",
    "trainFeaturesUpdated.add_columns([hasNeverBoughtCompany,hasNeverBoughtBrand,hasNeverBoughtCategory],['hasNeverBoughtCompany','hasNeverBoughtBrand','hasNeverBoughtCategory'])\n",
    "trainFeaturesUpdated.add_columns([hasBoughtCompanyBrand,hasBoughtCategoryBrand,hasBoughtCompanyCategory],['hasBoughtCompanyBrand','hasBoughtCategoryBrand','hasBoughtCompanyCategory'])\n",
    "\n",
    "hasBoughtCompanyBrand = 1*((testFeaturesUpdated['numCompany'] > 0)*(testFeaturesUpdated['numBrand'] > 0))\n",
    "hasBoughtCompanyCategory = 1*((testFeaturesUpdated['numCompany'] > 0)*(testFeaturesUpdated['numCategory'] > 0))\n",
    "hasBoughtCategoryBrand = 1*((testFeaturesUpdated['numCategory'] > 0)*(testFeaturesUpdated['numBrand'] > 0))\n",
    "testFeaturesUpdated.add_columns([hasBoughtCompanyBrand,hasBoughtCategoryBrand,hasBoughtCompanyCategory],['hasBoughtCompanyBrand','hasBoughtCategoryBrand','hasBoughtCompanyCategory'])\n",
    "\n",
    "hasBoughtCompanyBrandCategory = 1*((trainFeaturesUpdated['numCompany'] > 0)*(trainFeaturesUpdated['numBrand'] > 0)*(trainFeaturesUpdated['numCategory'] > 0))\n",
    "trainFeaturesUpdated.add_column(hasBoughtCompanyBrandCategory,'hasBoughtCompanyBrandCategory')\n",
    "\n",
    "hasBoughtCompanyBrandCategory = 1*((testFeaturesUpdated['numCompany'] > 0)*(testFeaturesUpdated['numBrand'] > 0)*(testFeaturesUpdated['numCategory'] > 0))\n",
    "testFeaturesUpdated.add_column(hasBoughtCompanyBrandCategory,'hasBoughtCompanyBrandCategory')\n",
    "\n",
    "hasNeverBoughtCompany = -1*((testFeaturesChange['numCompany'] == 0))\n",
    "hasNeverBoughtCategory = -1*((testFeaturesChange['numCategory'] == 0))\n",
    "hasNeverBoughtBrand = -1*((testFeaturesChange['numBrand'] == 0))\n",
    "testCheck1.add_columns([hasNeverBoughtCompany,hasNeverBoughtCategory, hasNeverBoughtBrand],['hasNeverBoughtCompany','hasNeverBoughtCategory','hasNeverBoughtBrand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "**************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some more features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemsBrandDate = items[:]\n",
    "itemsCategoryDate = items[:]\n",
    "itemsCompanyDate = items[:]\n",
    "itemsBrandDate.remove_columns(['chain', 'dept', 'productsize','productmeasure','category','company'])\n",
    "itemsCategoryDate.remove_columns(['chain', 'dept', 'productsize','productmeasure','brand','company'])\n",
    "itemsCompanyDate.remove_columns(['chain', 'dept', 'productsize','productmeasure','category','brand'])\n",
    "\n",
    "itemsBrandDate.remove_columns(['purchasequantity','purchaseamount'])\n",
    "itemsCategoryDate.remove_columns(['purchasequantity','purchaseamount'])\n",
    "itemsCompanyDate.remove_columns(['purchasequantity','purchaseamount'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "dictStore = {}\n",
    "date_format = \"%Y-%m-%d\"\n",
    "pattern = \"%Y-%m-%d\"\n",
    "lIdT = []\n",
    "l = []\n",
    "with open(\"trainFeatures.csv\") as f:\n",
    "    for i in xrange(1):\n",
    "        f.next()\n",
    "    for e, line in enumerate( f ):\n",
    "        dateNowString = line.split(\",\")[6]\n",
    "        dateNow = line.split(\",\")[6][1:len(dateNowString)-1]\n",
    "        ep = datetime.strptime(dateNow, date_format)\n",
    "        l = [int(line.split(\",\")[7]), int(line.split(\",\")[9]), int(line.split(\",\")[11]), ep]\n",
    "        dictStore[int(line.split(\",\")[0])] = l\n",
    "        #dictStore[line.split(\",\")[0]] = l\n",
    "        lIdT.append(int(line.split(\",\")[0]))\n",
    "        toc = time.time()\n",
    "print (toc - tic)\n",
    "print len(dictStore)\n",
    "print len(lIdT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "i = 0\n",
    "date_format = \"%Y-%m-%d\"\n",
    "listOfValuesBrand = []\n",
    "listOfValuesCompany = []\n",
    "listOfValuesCategory = []\n",
    "keyError = []\n",
    "for x in lIdT:\n",
    "    #print type(x)\n",
    "    i = i + 1\n",
    "    presentValues = [0,0,0,0,0,0,0]#15,30,60,90,120,150,180 in reverse\n",
    "    if((i % 50) == 0):\n",
    "        print (time.time()-tic), i\n",
    "    try:\n",
    "        xlist = listofIndices[x]\n",
    "        particularIdBrandDate = itemsBrandDate[xlist[0]:xlist[1]]#particular id is a sframe\n",
    "        particularIdCompanyDate = itemsCompanyDate[xlist[0]:xlist[1]]\n",
    "        particularIdCategoryDate = itemsCategoryDate[xlist[0]:xlist[1]]\n",
    "        listDictStore = dictStore[x]\n",
    "        dateNow = listDictStore[3]\n",
    "        \n",
    "        particularIdCategoryDate = particularIdCategoryDate.filter_by([listDictStore[0]], 'category')    \n",
    "        particularIdCategoryDate = list(particularIdCategoryDate['date'])\n",
    "        if(len(particularIdCategoryDate)!= 0):\n",
    "            for eachDate in reversed(particularIdCategoryDate):\n",
    "                eachDateNew = datetime.strptime(eachDate, date_format)\n",
    "                delta = dateNow - eachDateNew\n",
    "                daysDiff = delta.days\n",
    "                if(daysDiff < 15):\n",
    "                    presentValues = [x+1 for x in presentValues]\n",
    "                elif(daysDiff < 30):\n",
    "                    presentValues[:6] = [x+1 for x in presentValues[:6]]\n",
    "                elif(daysDiff < 60):\n",
    "                    presentValues[:5] = [x+1 for x in presentValues[:5]]\n",
    "                elif(daysDiff < 90):\n",
    "                    presentValues[:4] = [x+1 for x in presentValues[:4]]\n",
    "                elif(daysDiff < 120):\n",
    "                    presentValues[:3] = [x+1 for x in presentValues[:3]]\n",
    "                elif(daysDiff < 150):\n",
    "                    presentValues[:2] = [x+1 for x in presentValues[:2]]\n",
    "                elif(daysDiff < 180):\n",
    "                    presentValues[:1] = [x+1 for x in presentValues[:1]]\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "        listOfValuesCategory.append(presentValues)\n",
    "\n",
    "        presentValues = [0,0,0,0,0,0,0]\n",
    "        particularIdCompanyDate = particularIdCompanyDate.filter_by([listDictStore[1]], 'company')    \n",
    "        particularIdCompanyDate = list(particularIdCompanyDate['date'])\n",
    "        if(len(particularIdCompanyDate)!= 0):\n",
    "            for eachDate in reversed(particularIdCompanyDate):\n",
    "                eachDateNew = datetime.strptime(eachDate, date_format)\n",
    "                delta = dateNow - eachDateNew\n",
    "                daysDiff = delta.days\n",
    "                if(daysDiff < 15):\n",
    "                    presentValues = [x+1 for x in presentValues]\n",
    "                elif(daysDiff < 30):\n",
    "                    presentValues[:6] = [x+1 for x in presentValues[:6]]\n",
    "                elif(daysDiff < 60):\n",
    "                    presentValues[:5] = [x+1 for x in presentValues[:5]]\n",
    "                elif(daysDiff < 90):\n",
    "                    presentValues[:4] = [x+1 for x in presentValues[:4]]\n",
    "                elif(daysDiff < 120):\n",
    "                    presentValues[:3] = [x+1 for x in presentValues[:3]]\n",
    "                elif(daysDiff < 150):\n",
    "                    presentValues[:2] = [x+1 for x in presentValues[:2]]\n",
    "                elif(daysDiff < 180):\n",
    "                    presentValues[:1] = [x+1 for x in presentValues[:1]]\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "        listOfValuesCompany.append(presentValues)\n",
    "\n",
    "        presentValues = [0,0,0,0,0,0,0]\n",
    "        particularIdBrandDate = particularIdBrandDate.filter_by([listDictStore[2]], 'brand')    \n",
    "        particularIdBrandDate = list(particularIdBrandDate['date'])\n",
    "        if(len(particularIdBrandDate)!= 0):\n",
    "            for eachDate in reversed(particularIdBrandDate):\n",
    "                eachDateNew = datetime.strptime(eachDate, date_format)\n",
    "                delta = dateNow - eachDateNew\n",
    "                daysDiff = delta.days\n",
    "                if(daysDiff < 15):\n",
    "                    presentValues = [x+1 for x in presentValues]\n",
    "                elif(daysDiff < 30):\n",
    "                    presentValues[:6] = [x+1 for x in presentValues[:6]]\n",
    "                elif(daysDiff < 60):\n",
    "                    presentValues[:5] = [x+1 for x in presentValues[:5]]\n",
    "                elif(daysDiff < 90):\n",
    "                    presentValues[:4] = [x+1 for x in presentValues[:4]]\n",
    "                elif(daysDiff < 120):\n",
    "                    presentValues[:3] = [x+1 for x in presentValues[:3]]\n",
    "                elif(daysDiff < 150):\n",
    "                    presentValues[:2] = [x+1 for x in presentValues[:2]]\n",
    "                elif(daysDiff < 180):\n",
    "                    presentValues[:1] = [x+1 for x in presentValues[:1]]\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "        listOfValuesBrand.append(presentValues)\n",
    "\n",
    "    except:\n",
    "        keyError.append(x)\n",
    "        #print x\n",
    "\n",
    "toc = time.time()\n",
    "print (toc-tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "**********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding few more features, Making a model and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "i = 0\n",
    "numberOfTransactions = []\n",
    "keyError = []\n",
    "for x in lIdT:\n",
    "    try:\n",
    "        xNum = listofIndices[x]\n",
    "        numberOfTransactions.append(xNum)\n",
    "    except:\n",
    "        numberOfTransactions.append(100000000)\n",
    "\n",
    "toc = time.time()\n",
    "print (toc-tic)\n",
    "\n",
    "trainFeaturesChange = gl.load_sframe('./trainFeaturesUpdated')\n",
    "testFeaturesChange = gl.load_sframe('./testFeaturesUpdated')\n",
    "trainFeaturesChange.remove_column('offerdate')\n",
    "testFeaturesChange.remove_column('offerdate')\n",
    "\n",
    "numberOfTransactions = SArray(numberOfTransactions)\n",
    "trainFeaturesChange.add_column(numberOfTransactions, 'numberOfTransactions')\n",
    "companyLoyalty = trainFeaturesChange['numCompany']/trainFeaturesChange['numberOfTransactions'] \n",
    "trainFeaturesChange.add_column(companyLoyalty, 'companyLoyalty')\n",
    "categoryLoyalty = trainFeaturesChange['numCategory']/trainFeaturesChange['numberOfTransactions'] \n",
    "trainFeaturesChange.add_column(categoryLoyalty, 'categoryLoyalty')\n",
    "\n",
    "tic = time.time()\n",
    "i = 0\n",
    "numberOfTransactions = []\n",
    "keyError = []\n",
    "for x in lIdTTest:\n",
    "    try:\n",
    "        xNum = listofIndices[x]\n",
    "        numberOfTransactions.append(xNum)\n",
    "    except:\n",
    "        numberOfTransactions.append(100000000)\n",
    "\n",
    "toc = time.time()\n",
    "print (toc-tic)\n",
    "\n",
    "brandLoyalty = testFeaturesChange['numBrand']/testFeaturesChange['numberOfTransactions'] \n",
    "testFeaturesChange.add_column(brandLoyalty, 'brandLoyalty')\n",
    "companyLoyalty = testFeaturesChange['numCompany']/testFeaturesChange['numberOfTransactions'] \n",
    "testFeaturesChange.add_column(companyLoyalty, 'companyLoyalty')\n",
    "categoryLoyalty = testFeaturesChange['numCategory']/testFeaturesChange['numberOfTransactions'] \n",
    "testFeaturesChange.add_column(categoryLoyalty, 'categoryLoyalty')\n",
    "\n",
    "trainCheck = trainFeaturesChange[(trainFeaturesChange['amountCategory'] <= 305) & (trainFeaturesChange['amountCategory'] >= 0)]\n",
    "trainCheck = trainCheck[(trainCheck['amountCompany'] <= 380) & (trainCheck['amountCompany'] >= 0)]\n",
    "trainCheck = trainCheck[(trainCheck['amountBrand'] <= 210) & (trainCheck['amountBrand'] >= 0)]\n",
    "print len(trainCheck)\n",
    "\n",
    "trainCheck1 = trainCheck[:]\n",
    "hasNotBoughtAny180 = -1*((trainCheck['company180'] == 0)*(trainCheck['category180'] == 0)*(trainCheck['brand180'] == 0))\n",
    "hasBoughtAll15 = 1*((trainCheck['company15'] > 0)*(trainCheck['category15'] > 0)*(trainCheck['brand15'] > 0))\n",
    "trainCheck1.add_columns([hasNotBoughtAny180,hasBoughtAll15],['hasNotBoughtAny180','hasBoughtAll15'])\n",
    "testCheck1 = testFeaturesChange[:]\n",
    "hasNotBoughtAny180 = -1*((testFeaturesChange['company180'] == 0)*(testFeaturesChange['category180'] == 0)*(testFeaturesChange['brand180'] == 0))\n",
    "hasBoughtAll15 = 1*((testFeaturesChange['company15'] > 0)*(testFeaturesChange['category15'] > 0)*(testFeaturesChange['brand15'] > 0))\n",
    "testCheck1.add_columns([hasNotBoughtAny180,hasBoughtAll15],['hasNotBoughtAny180','hasBoughtAll15'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "***************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------Random Forest Classifier--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= gl.random_forest_classifier.create(trainCheck1,target = 'repeater', verbose = True, class_weights = 'auto')\n",
    "predictions = model.classify(testCheck1)\n",
    "upload = testCheck1['id', 'numBrand']\n",
    "upload.remove_column('numBrand')\n",
    "upload.add_column(predictions['probability'], 'repeatProbability')\n",
    "upload.export_csv('submit.csv', delimiter = ',', line_terminator = '\\n', header = True, quote_level=2, quote_char = '\"', na_rep = 'NA', file_header = '', file_footer = '', line_prefix = '', _no_prefix_on_first_value=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
